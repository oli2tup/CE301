{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malaria_classification_using_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBkYlE3j2n3ZdqRW0vsJau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oli2tup/CE301/blob/main/Malaria_classification_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsPL_RDOEPU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b70fd78-1669-4648-fcbb-70fc0ecf3a0a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, MaxPool2D\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tinc43FDURmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c51df65-8c05-4fdc-85cd-3a1d5a25a1d3"
      },
      "source": [
        "!git clone https://github.com/oli2tup/CE301.git\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CE301' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnAGtSTdkZlA"
      },
      "source": [
        "img_width = 100\n",
        "img_height = 100"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSUVfOqCkkEf"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2) # using 20% of data as validation"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp3y6HX6kz1O",
        "outputId": "18228d7f-f2ed-446d-dcc1-9d28b27224f5"
      },
      "source": [
        "train_data_generator = datagen.flow_from_directory(\n",
        "    directory ='/content/CE301/cell_images', target_size =(img_width, img_height),\n",
        "    class_mode = 'binary',\n",
        "    batch_size = 16,\n",
        "    subset = 'training'\n",
        ") # Training subset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22048 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8p_umi9nhU4",
        "outputId": "80b7eb1b-4afd-4456-a693-a0249143e7fc"
      },
      "source": [
        "validation_data_generator = datagen.flow_from_directory(\n",
        "    directory ='/content/CE301/cell_images', target_size =(img_width, img_height),\n",
        "    class_mode = 'binary',\n",
        "    batch_size = 16,\n",
        "    subset = 'validation'\n",
        ") # Validation subset"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5510 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUFgheZJnzqI",
        "outputId": "edf56498-f55b-44a7-8c58-9069776992c2"
      },
      "source": [
        "train_data_generator.labels"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baoMFHp2n7AP",
        "outputId": "c8bc7784-1870-4d49-db8c-99803193d36b"
      },
      "source": [
        "validation_data_generator.labels"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vtPSHOKDR6e"
      },
      "source": [
        "class ResidualUnit(keras.layers.Layer):\n",
        "  def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.activation = keras.activations.get(activation)\n",
        "    self.main_layers = [\n",
        "      keras.layers.Conv2D(filters, 3, strides=strides,\n",
        "        padding=\"same\", use_bias=False),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      self.activation,\n",
        "      keras.layers.Conv2D(filters, 3, strides=1,\n",
        "        padding=\"same\", use_bias=False),\n",
        "      keras.layers.BatchNormalization()]\n",
        "    self.skip_layers = []\n",
        "    if strides > 1:\n",
        "      self.skip_layers = [\n",
        "        keras.layers.Conv2D(filters, 1, strides=strides,\n",
        "          padding=\"same\", use_bias=False),\n",
        "        keras.layers.BatchNormalization()]\n",
        "  def call(self, inputs):\n",
        "    Z  = inputs\n",
        "    for layer in self.main_layers:\n",
        "      Z = layer(Z)\n",
        "    skip_Z = inputs\n",
        "    for layer in self.skip_layers:\n",
        "      skip_Z = layer(skip_Z)\n",
        "      return self.activation(Z + skip_Z)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}